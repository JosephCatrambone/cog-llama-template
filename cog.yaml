# Configuration for Cog ⚙️
# Reference: https://github.com/replicate/cog/blob/main/docs/yaml.md

build:
  # set to true if your model requires a GPU
  gpu: true
  cuda: "11.8"

  # python version in the form '3.8' or '3.8.12'
  python_version: "3.11"

  # a list of packages in the format <package-name>==<version>
  python_packages:
    - "numpy==1.25.1"
    - "torch==2.0.1"
    - "accelerate==0.21.0"
    - "peft==0.4.0"
    - "sentencepiece==0.1.99"
    - "tensorizer==1.0.1"
    - "jinja2==3.1.2"
    - "deepspeed==0.10.0"
    - "vllm==0.1.2"


  run: 
  #- "pip install git+https://github.com/huggingface/transformers.git@786092a35e18154cacad62c30fe92bac2c27a1e1"
    - "pip install transformers==4.28"
    - "mkdir /gc && cd /gc && curl -O https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-cli-426.0.0-linux-x86_64.tar.gz && tar -xf google-cloud-cli-426.0.0-linux-x86_64.tar.gz && ./google-cloud-sdk/install.sh -q"
    - "pip install google-cloud-storage"
    - "pip install protobuf==3.19"
    

# predict.py defines how predictions are run on your model
predict: "predict.py:VLLMPredictor"
train: "train.py:train"
